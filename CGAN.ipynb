{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6SCR8KYDcZA9"
   },
   "outputs": [],
   "source": [
    "# Pytorch libraries\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "# classic libraries\n",
    "import numpy as np\n",
    "\n",
    "import errno\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "\n",
    "\n",
    "def create_folder(folder_path):\n",
    "    \"\"\"Create a folder if it does not exist.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        os.makedirs(folder_path)\n",
    "    except OSError as _e:\n",
    "        if _e.errno != errno.EEXIST:\n",
    "            raise\n",
    "\n",
    "\n",
    "def to_np(var):\n",
    "    \"\"\"Exports torch.Tensor to Numpy array.\n",
    "    \"\"\"\n",
    "    return var.detach().cpu().numpy()\n",
    "\n",
    "def clear_folder(folder_path):\n",
    "    \"\"\"Clear all contents recursively if the folder exists.\n",
    "    Create the folder if it has been accidently deleted.\n",
    "    \"\"\"\n",
    "    create_folder(folder_path)\n",
    "    for the_file in os.listdir(folder_path):\n",
    "        _file_path = os.path.join(folder_path, the_file)\n",
    "        try:\n",
    "            if os.path.isfile(_file_path):\n",
    "                os.unlink(_file_path)\n",
    "            elif os.path.isdir(_file_path):\n",
    "                shutil.rmtree(_file_path)\n",
    "        except OSError as _e:\n",
    "            print(_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SYMpPbJccn0n"
   },
   "outputs": [],
   "source": [
    "# Pytorch libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# classic libraries\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "CUDA = True\n",
    "data_dir = '../dataset/fashionmnist'\n",
    "out_dir = '../output'\n",
    "epochs=3\n",
    "#LOG_FILE = os.path.join(OUT_PATH, 'log.txt')\n",
    "batch_size = 128\n",
    "lr = 0.0002\n",
    "latent_dim=100\n",
    "classes = 10\n",
    "img_size = 64\n",
    "log_interval=100\n",
    "channels=1\n",
    "train=True\n",
    "seed = 1\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, classes, channels, img_size, latent_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.classes = classes\n",
    "        self.channels = channels\n",
    "        self.img_size = img_size\n",
    "        self.latent_dim = latent_dim\n",
    "        self.img_shape = (self.channels, self.img_size, self.img_size)\n",
    "        self.label_embedding = nn.Embedding(self.classes, self.classes)\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *self._create_layer(self.latent_dim + self.classes, 128, False),\n",
    "            *self._create_layer(128, 256),\n",
    "            *self._create_layer(256, 512),\n",
    "            *self._create_layer(512, 1024),\n",
    "            nn.Linear(1024, int(np.prod(self.img_shape))),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def _create_layer(self, size_in, size_out, normalize=True):\n",
    "        layers = [nn.Linear(size_in, size_out)]\n",
    "        if normalize:\n",
    "            layers.append(nn.BatchNorm1d(size_out))\n",
    "        layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "        return layers\n",
    "\n",
    "    def forward(self, noise, labels):\n",
    "        z = torch.cat((self.label_embedding(labels), noise), -1)\n",
    "        x = self.model(z)\n",
    "        x = x.view(x.size(0), *self.img_shape)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, classes, channels, img_size, latent_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.classes = classes\n",
    "        self.channels = channels\n",
    "        self.img_size = img_size\n",
    "        self.latent_dim = latent_dim\n",
    "        self.img_shape = (self.channels, self.img_size, self.img_size)\n",
    "        self.label_embedding = nn.Embedding(self.classes, self.classes)\n",
    "        self.adv_loss = torch.nn.BCELoss()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *self._create_layer(self.classes + int(np.prod(self.img_shape)), 1024, False, True),\n",
    "            *self._create_layer(1024, 512, True, True),\n",
    "            *self._create_layer(512, 256, True, True),\n",
    "            *self._create_layer(256, 128, False, False),\n",
    "            *self._create_layer(128, 1, False, False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def _create_layer(self, size_in, size_out, drop_out=True, act_func=True):\n",
    "        layers = [nn.Linear(size_in, size_out)]\n",
    "        if drop_out:\n",
    "            layers.append(nn.Dropout(0.4))\n",
    "        if act_func:\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "        return layers\n",
    "\n",
    "    def forward(self, image, labels):\n",
    "        x = torch.cat((image.view(image.size(0), -1), self.label_embedding(labels)), -1)\n",
    "        return self.model(x)\n",
    "\n",
    "    def loss(self, output, label):\n",
    "        return self.adv_loss(output, label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "bg8N0fo9c3Fi",
    "outputId": "31edc896-becc-419c-b70a-6aa96848177c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.4.0\n",
      "CUDA version: 10.1\n",
      "\n",
      "Random Seed:  1\n",
      "Generator(\n",
      "  (label_embedding): Embedding(10, 10)\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=110, out_features=128, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Linear(in_features=128, out_features=256, bias=True)\n",
      "    (3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (5): Linear(in_features=256, out_features=512, bias=True)\n",
      "    (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (8): Linear(in_features=512, out_features=1024, bias=True)\n",
      "    (9): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (11): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "    (12): Tanh()\n",
      "  )\n",
      ")\n",
      "generator params 4906212\n",
      "Discriminator(\n",
      "  (label_embedding): Embedding(10, 10)\n",
      "  (adv_loss): BCELoss()\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=4106, out_features=1024, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (3): Dropout(p=0.4, inplace=False)\n",
      "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (5): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (6): Dropout(p=0.4, inplace=False)\n",
      "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (8): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (9): Linear(in_features=128, out_features=1, bias=True)\n",
      "    (10): Sigmoid()\n",
      "  )\n",
      ")\n",
      "discrimator params 4894821\n",
      "Epoch 0 [100/469] loss_D: 0.2796 loss_G: 1.2264 time: 4.02\n",
      "Epoch 0 [200/469] loss_D: 0.4489 loss_G: 0.7464 time: 2.78\n",
      "Epoch 0 [300/469] loss_D: 0.5001 loss_G: 2.2147 time: 2.75\n",
      "Epoch 0 [400/469] loss_D: 0.3859 loss_G: 3.0233 time: 2.81\n",
      "\n",
      "Saving models to CGAN_0_G.pt and CGAN_0_D.pt ...\n",
      "Epoch 1 [100/469] loss_D: 0.6299 loss_G: 3.8329 time: 3.81\n",
      "Epoch 1 [200/469] loss_D: 0.5285 loss_G: 1.9740 time: 2.80\n",
      "Epoch 1 [300/469] loss_D: 0.4439 loss_G: 1.4392 time: 2.81\n",
      "Epoch 1 [400/469] loss_D: 0.4902 loss_G: 1.6140 time: 3.02\n",
      "\n",
      "Saving models to CGAN_1_G.pt and CGAN_1_D.pt ...\n",
      "Epoch 2 [100/469] loss_D: 0.3726 loss_G: 1.8487 time: 4.01\n",
      "Epoch 2 [200/469] loss_D: 0.4642 loss_G: 1.2868 time: 3.06\n",
      "Epoch 2 [300/469] loss_D: 0.4306 loss_G: 1.9561 time: 2.92\n",
      "Epoch 2 [400/469] loss_D: 0.4903 loss_G: 1.3095 time: 2.80\n",
      "\n",
      "Saving models to CGAN_2_G.pt and CGAN_2_D.pt ...\n",
      "Epoch 3 [100/469] loss_D: 0.4976 loss_G: 1.6507 time: 3.99\n",
      "Epoch 3 [200/469] loss_D: 0.4953 loss_G: 1.0936 time: 2.82\n",
      "Epoch 3 [300/469] loss_D: 0.6245 loss_G: 0.6177 time: 2.91\n",
      "Epoch 3 [400/469] loss_D: 0.5518 loss_G: 1.0872 time: 2.79\n",
      "\n",
      "Saving models to CGAN_3_G.pt and CGAN_3_D.pt ...\n",
      "Epoch 4 [100/469] loss_D: 0.6112 loss_G: 0.7126 time: 3.82\n",
      "Epoch 4 [200/469] loss_D: 0.5512 loss_G: 1.1372 time: 2.94\n",
      "Epoch 4 [300/469] loss_D: 0.5724 loss_G: 1.5212 time: 2.78\n",
      "Epoch 4 [400/469] loss_D: 0.5676 loss_G: 0.8793 time: 3.00\n",
      "\n",
      "Saving models to CGAN_4_G.pt and CGAN_4_D.pt ...\n",
      "Epoch 5 [100/469] loss_D: 0.5609 loss_G: 2.0486 time: 4.05\n",
      "Epoch 5 [200/469] loss_D: 0.5494 loss_G: 1.0140 time: 2.90\n",
      "Epoch 5 [300/469] loss_D: 0.5654 loss_G: 0.9832 time: 2.96\n",
      "Epoch 5 [400/469] loss_D: 0.6383 loss_G: 0.6965 time: 2.80\n",
      "\n",
      "Saving models to CGAN_5_G.pt and CGAN_5_D.pt ...\n",
      "Epoch 6 [100/469] loss_D: 0.5858 loss_G: 1.1463 time: 3.81\n",
      "Epoch 6 [200/469] loss_D: 0.6510 loss_G: 0.9489 time: 2.77\n",
      "Epoch 6 [300/469] loss_D: 0.4864 loss_G: 1.5971 time: 2.79\n",
      "Epoch 6 [400/469] loss_D: 0.5828 loss_G: 0.9617 time: 2.79\n",
      "\n",
      "Saving models to CGAN_6_G.pt and CGAN_6_D.pt ...\n",
      "Epoch 7 [100/469] loss_D: 0.5872 loss_G: 1.0962 time: 3.99\n",
      "Epoch 7 [200/469] loss_D: 0.5508 loss_G: 0.8970 time: 2.84\n",
      "Epoch 7 [300/469] loss_D: 0.5214 loss_G: 1.8606 time: 2.78\n",
      "Epoch 7 [400/469] loss_D: 0.5266 loss_G: 1.1227 time: 2.77\n",
      "\n",
      "Saving models to CGAN_7_G.pt and CGAN_7_D.pt ...\n",
      "Epoch 8 [100/469] loss_D: 0.6180 loss_G: 1.1092 time: 3.84\n",
      "Epoch 8 [200/469] loss_D: 0.6031 loss_G: 1.1758 time: 3.00\n",
      "Epoch 8 [300/469] loss_D: 0.6035 loss_G: 1.5151 time: 2.79\n",
      "Epoch 8 [400/469] loss_D: 0.9202 loss_G: 3.4529 time: 2.73\n",
      "\n",
      "Saving models to CGAN_8_G.pt and CGAN_8_D.pt ...\n",
      "Epoch 9 [100/469] loss_D: 0.5700 loss_G: 1.1754 time: 3.80\n",
      "Epoch 9 [200/469] loss_D: 0.5775 loss_G: 1.0367 time: 2.74\n",
      "Epoch 9 [300/469] loss_D: 0.5785 loss_G: 0.9877 time: 2.85\n",
      "Epoch 9 [400/469] loss_D: 0.5480 loss_G: 1.3571 time: 2.82\n",
      "\n",
      "Saving models to CGAN_9_G.pt and CGAN_9_D.pt ...\n",
      "Epoch 10 [100/469] loss_D: 0.4859 loss_G: 1.6841 time: 3.98\n",
      "Epoch 10 [200/469] loss_D: 0.5844 loss_G: 1.3387 time: 2.92\n",
      "Epoch 10 [300/469] loss_D: 0.6153 loss_G: 0.8426 time: 2.86\n",
      "Epoch 10 [400/469] loss_D: 0.5554 loss_G: 1.5803 time: 2.87\n",
      "\n",
      "Saving models to CGAN_10_G.pt and CGAN_10_D.pt ...\n",
      "Epoch 11 [100/469] loss_D: 0.6911 loss_G: 0.5320 time: 3.95\n",
      "Epoch 11 [200/469] loss_D: 0.6269 loss_G: 0.9142 time: 2.83\n",
      "Epoch 11 [300/469] loss_D: 0.6539 loss_G: 0.7685 time: 2.93\n",
      "Epoch 11 [400/469] loss_D: 0.5844 loss_G: 0.9937 time: 2.82\n",
      "\n",
      "Saving models to CGAN_11_G.pt and CGAN_11_D.pt ...\n",
      "Epoch 12 [100/469] loss_D: 0.5873 loss_G: 1.0577 time: 3.88\n",
      "Epoch 12 [200/469] loss_D: 0.7110 loss_G: 1.5461 time: 2.98\n",
      "Epoch 12 [300/469] loss_D: 0.5207 loss_G: 2.2758 time: 2.81\n",
      "Epoch 12 [400/469] loss_D: 0.6091 loss_G: 0.9346 time: 2.77\n",
      "\n",
      "Saving models to CGAN_12_G.pt and CGAN_12_D.pt ...\n",
      "Epoch 13 [100/469] loss_D: 0.5302 loss_G: 2.1877 time: 3.83\n",
      "Epoch 13 [200/469] loss_D: 0.5507 loss_G: 1.5383 time: 2.83\n",
      "Epoch 13 [300/469] loss_D: 0.7492 loss_G: 0.4978 time: 2.80\n",
      "Epoch 13 [400/469] loss_D: 0.6687 loss_G: 1.1264 time: 2.88\n",
      "\n",
      "Saving models to CGAN_13_G.pt and CGAN_13_D.pt ...\n",
      "Epoch 14 [100/469] loss_D: 0.6272 loss_G: 0.8053 time: 3.84\n",
      "Epoch 14 [200/469] loss_D: 0.5655 loss_G: 1.0455 time: 2.80\n",
      "Epoch 14 [300/469] loss_D: 0.6435 loss_G: 1.1253 time: 2.79\n",
      "Epoch 14 [400/469] loss_D: 0.6126 loss_G: 0.8722 time: 2.90\n",
      "\n",
      "Saving models to CGAN_14_G.pt and CGAN_14_D.pt ...\n",
      "Epoch 15 [100/469] loss_D: 0.5442 loss_G: 1.2810 time: 3.99\n",
      "Epoch 15 [200/469] loss_D: 0.9209 loss_G: 0.2624 time: 2.93\n",
      "Epoch 15 [300/469] loss_D: 0.5797 loss_G: 1.1540 time: 2.81\n",
      "Epoch 15 [400/469] loss_D: 0.6223 loss_G: 1.0224 time: 2.82\n",
      "\n",
      "Saving models to CGAN_15_G.pt and CGAN_15_D.pt ...\n",
      "Epoch 16 [100/469] loss_D: 0.5173 loss_G: 0.9745 time: 3.94\n",
      "Epoch 16 [200/469] loss_D: 0.5878 loss_G: 0.7843 time: 2.88\n",
      "Epoch 16 [300/469] loss_D: 0.5572 loss_G: 1.1899 time: 2.81\n",
      "Epoch 16 [400/469] loss_D: 0.5693 loss_G: 1.1545 time: 2.80\n",
      "\n",
      "Saving models to CGAN_16_G.pt and CGAN_16_D.pt ...\n",
      "Epoch 17 [100/469] loss_D: 0.5607 loss_G: 1.0817 time: 3.80\n",
      "Epoch 17 [200/469] loss_D: 0.5895 loss_G: 1.7513 time: 2.81\n",
      "Epoch 17 [300/469] loss_D: 0.6409 loss_G: 0.7239 time: 2.79\n",
      "Epoch 17 [400/469] loss_D: 0.5855 loss_G: 0.7886 time: 3.01\n",
      "\n",
      "Saving models to CGAN_17_G.pt and CGAN_17_D.pt ...\n",
      "Epoch 18 [100/469] loss_D: 0.6479 loss_G: 1.6899 time: 3.80\n",
      "Epoch 18 [200/469] loss_D: 0.5437 loss_G: 0.9473 time: 2.90\n",
      "Epoch 18 [300/469] loss_D: 0.6341 loss_G: 0.6267 time: 2.98\n",
      "Epoch 18 [400/469] loss_D: 0.6232 loss_G: 0.7886 time: 2.87\n",
      "\n",
      "Saving models to CGAN_18_G.pt and CGAN_18_D.pt ...\n",
      "Epoch 19 [100/469] loss_D: 0.5679 loss_G: 1.0352 time: 4.07\n",
      "Epoch 19 [200/469] loss_D: 0.6410 loss_G: 1.1016 time: 2.79\n",
      "Epoch 19 [300/469] loss_D: 0.6784 loss_G: 0.4797 time: 2.78\n",
      "Epoch 19 [400/469] loss_D: 0.5852 loss_G: 1.1218 time: 2.78\n",
      "\n",
      "Saving models to CGAN_19_G.pt and CGAN_19_D.pt ...\n",
      "Epoch 20 [100/469] loss_D: 0.6080 loss_G: 1.0956 time: 3.84\n",
      "Epoch 20 [200/469] loss_D: 0.6053 loss_G: 0.9874 time: 2.93\n",
      "Epoch 20 [300/469] loss_D: 0.6417 loss_G: 1.5405 time: 2.85\n",
      "Epoch 20 [400/469] loss_D: 0.6402 loss_G: 1.4304 time: 3.00\n",
      "\n",
      "Saving models to CGAN_20_G.pt and CGAN_20_D.pt ...\n",
      "Epoch 21 [100/469] loss_D: 0.5524 loss_G: 0.9442 time: 3.95\n",
      "Epoch 21 [200/469] loss_D: 0.5954 loss_G: 0.9031 time: 2.85\n",
      "Epoch 21 [300/469] loss_D: 0.5560 loss_G: 1.0462 time: 2.95\n",
      "Epoch 21 [400/469] loss_D: 0.5685 loss_G: 1.0104 time: 2.90\n",
      "\n",
      "Saving models to CGAN_21_G.pt and CGAN_21_D.pt ...\n",
      "Epoch 22 [100/469] loss_D: 0.5499 loss_G: 0.8157 time: 3.96\n",
      "Epoch 22 [200/469] loss_D: 0.6169 loss_G: 0.7130 time: 3.06\n",
      "Epoch 22 [300/469] loss_D: 0.5734 loss_G: 1.0636 time: 2.85\n",
      "Epoch 22 [400/469] loss_D: 0.5782 loss_G: 0.9388 time: 2.82\n",
      "\n",
      "Saving models to CGAN_22_G.pt and CGAN_22_D.pt ...\n",
      "Epoch 23 [100/469] loss_D: 0.5810 loss_G: 1.0274 time: 3.98\n",
      "Epoch 23 [200/469] loss_D: 0.6884 loss_G: 0.6216 time: 2.80\n",
      "Epoch 23 [300/469] loss_D: 0.5412 loss_G: 1.4459 time: 2.95\n",
      "Epoch 23 [400/469] loss_D: 0.5039 loss_G: 1.4121 time: 2.97\n",
      "\n",
      "Saving models to CGAN_23_G.pt and CGAN_23_D.pt ...\n",
      "Epoch 24 [100/469] loss_D: 0.5160 loss_G: 1.2566 time: 4.05\n",
      "Epoch 24 [200/469] loss_D: 0.5472 loss_G: 1.0159 time: 2.91\n",
      "Epoch 24 [300/469] loss_D: 0.6007 loss_G: 1.1241 time: 2.83\n",
      "Epoch 24 [400/469] loss_D: 0.9157 loss_G: 0.2789 time: 2.79\n",
      "\n",
      "Saving models to CGAN_24_G.pt and CGAN_24_D.pt ...\n",
      "Epoch 25 [100/469] loss_D: 0.5506 loss_G: 0.8365 time: 4.26\n",
      "Epoch 25 [200/469] loss_D: 0.5535 loss_G: 1.1479 time: 2.81\n",
      "Epoch 25 [300/469] loss_D: 0.5629 loss_G: 1.0564 time: 2.87\n",
      "Epoch 25 [400/469] loss_D: 0.5769 loss_G: 1.1889 time: 2.83\n",
      "\n",
      "Saving models to CGAN_25_G.pt and CGAN_25_D.pt ...\n",
      "Epoch 26 [100/469] loss_D: 0.5549 loss_G: 1.0259 time: 4.02\n",
      "Epoch 26 [200/469] loss_D: 0.5668 loss_G: 0.9947 time: 3.02\n",
      "Epoch 26 [300/469] loss_D: 0.6495 loss_G: 0.9000 time: 2.86\n",
      "Epoch 26 [400/469] loss_D: 0.5386 loss_G: 1.1777 time: 2.86\n",
      "\n",
      "Saving models to CGAN_26_G.pt and CGAN_26_D.pt ...\n",
      "Epoch 27 [100/469] loss_D: 0.6043 loss_G: 0.8926 time: 3.94\n",
      "Epoch 27 [200/469] loss_D: 0.6077 loss_G: 0.8163 time: 2.83\n",
      "Epoch 27 [300/469] loss_D: 0.5848 loss_G: 0.9454 time: 2.87\n",
      "Epoch 27 [400/469] loss_D: 0.5741 loss_G: 1.6972 time: 2.97\n",
      "\n",
      "Saving models to CGAN_27_G.pt and CGAN_27_D.pt ...\n",
      "Epoch 28 [100/469] loss_D: 0.5688 loss_G: 1.2515 time: 3.97\n",
      "Epoch 28 [200/469] loss_D: 0.5654 loss_G: 0.8665 time: 2.96\n",
      "Epoch 28 [300/469] loss_D: 0.6113 loss_G: 0.9329 time: 2.82\n",
      "Epoch 28 [400/469] loss_D: 0.6239 loss_G: 0.9305 time: 2.78\n",
      "\n",
      "Saving models to CGAN_28_G.pt and CGAN_28_D.pt ...\n",
      "Epoch 29 [100/469] loss_D: 0.6333 loss_G: 0.6806 time: 3.85\n",
      "Epoch 29 [200/469] loss_D: 0.6677 loss_G: 1.0906 time: 2.94\n",
      "Epoch 29 [300/469] loss_D: 0.6267 loss_G: 1.0304 time: 2.86\n",
      "Epoch 29 [400/469] loss_D: 0.6544 loss_G: 0.9713 time: 2.83\n",
      "\n",
      "Saving models to CGAN_29_G.pt and CGAN_29_D.pt ...\n",
      "Total train time: 463.29\n"
     ]
    }
   ],
   "source": [
    "# Pytorch libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "# classic libraries\n",
    "import numpy as np\n",
    "#import statsmodels.api as sm    # to estimate an average with 'loess'\n",
    "import matplotlib.pyplot as plt\n",
    "#from matplotlib import rc\n",
    "#rc('font', **font)\n",
    "#rc('text', usetex=True)\n",
    "import pandas as pd\n",
    "import random, string\n",
    "import os, time, datetime, json\n",
    "# perso libraries\n",
    "font = {'family' : 'DejaVu Sans',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 14}\n",
    "#rc('font', **font)\n",
    "#rc('text', usetex=True)\n",
    "import pandas as pd\n",
    "import random, string\n",
    "import os, time, datetime, json\n",
    "#-------------------------------------------------#\n",
    "#               A) Hyper-parameters               #\n",
    "#-------------------------------------------------#\n",
    "CUDA = True\n",
    "data_dir = '../dataset/fashionmnist'\n",
    "out_dir = '../output'\n",
    "epochs=30\n",
    "#LOG_FILE = os.path.join(OUT_PATH, 'log.txt')\n",
    "batch_size = 128\n",
    "lr = 0.0002\n",
    "latent_dim=100\n",
    "classes = 10\n",
    "img_size = 64\n",
    "log_interval=100\n",
    "channels=1\n",
    "train=True\n",
    "seed = 1\n",
    "#-------------------------------------------------#\n",
    "#               B) Data/Model/Loss                #\n",
    "#-------------------------------------------------#\n",
    "# B.1) dataset/corpus\n",
    "#--------------------\n",
    "# Corpus\n",
    "# print the number of parameters\n",
    "\n",
    "\n",
    "        \n",
    "clear_folder(out_dir)\n",
    "#print(\"Logging to {}\\n\".format(LOG_FILE))\n",
    "#sys.stdout = utils.StdOut(LOG_FILE)\n",
    "CUDA = CUDA and torch.cuda.is_available()\n",
    "print(\"PyTorch version: {}\".format(torch.__version__))\n",
    "if CUDA:\n",
    "    print(\"CUDA version: {}\\n\".format(torch.version.cuda))\n",
    "if seed is None:\n",
    "    seed = np.random.randint(1, 10000)\n",
    "print(\"Random Seed: \", seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if CUDA:\n",
    "    torch.cuda.manual_seed(seed)\n",
    "cudnn.benchmark = True\n",
    "device = torch.device(\"cuda:0\" if CUDA else \"cpu\")\n",
    "\n",
    "def _to_onehot(var, dim):\n",
    "        res = torch.zeros((var.shape[0], dim), device=device)\n",
    "        res[range(var.shape[0]), var] = 1.\n",
    "        return res\n",
    "\n",
    "def save_to(name=None,\n",
    "                verbose=True):\n",
    "        if verbose:\n",
    "            print('\\nSaving models to {}_G.pt and {}_D.pt ...'.format(name, name))\n",
    "        torch.save(netG.state_dict(), os.path.join(out_dir, '{}_G.pt'.format(name)))\n",
    "        torch.save(netD.state_dict(), os.path.join(out_dir, '{}_D.pt'.format(name)))\n",
    "\n",
    "\n",
    "dataset = dset.FashionMNIST(root=data_dir, download=True,\n",
    "                     transform=transforms.Compose([\n",
    "                     transforms.Resize(img_size),\n",
    "                     transforms.ToTensor(),\n",
    "                     transforms.Normalize((0.5,), (0.5,))\n",
    "                     ]))\n",
    "\n",
    "assert dataset\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=16, pin_memory=True)\n",
    "\n",
    "netG = Generator( classes, channels, img_size, latent_dim).to(device)\n",
    "#netG.apply(weights_init)\n",
    "print(netG)\n",
    "nbr_param = sum(p.numel() for p in netG.parameters() if p.requires_grad)\n",
    "print(\"generator params\", nbr_param)\n",
    "\n",
    "netD = Discriminator(classes, channels, img_size, latent_dim).to(device)\n",
    "#netD.apply(weights_init)\n",
    "print(netD)\n",
    "nbr_param = sum(p.numel() for p in netD.parameters() if p.requires_grad)\n",
    "print(\"discrimator params\", nbr_param)\n",
    "\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "netG.train()\n",
    "netD.train()\n",
    "viz_z = torch.zeros((batch_size, latent_dim), device=device)\n",
    "viz_noise = torch.randn(dataloader.batch_size, latent_dim, device=device)\n",
    "nrows = dataloader.batch_size // 8\n",
    "viz_label = torch.LongTensor(np.array([num for _ in range(nrows) for num in range(8)])).to(device)\n",
    "viz_onehot = _to_onehot(viz_label, dim=classes)\n",
    "total_time = time.time()\n",
    "for epoch in range(epochs):\n",
    "    batch_time = time.time()\n",
    "    for batch_idx, (data, target) in enumerate(dataloader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        batch_size = data.size(0)\n",
    "        real_label = torch.full((batch_size, 1), 1., device=device)\n",
    "        fake_label = torch.full((batch_size, 1), 0., device=device)\n",
    "        # Train G\n",
    "        netG.zero_grad()\n",
    "        z_noise = torch.randn(batch_size, latent_dim, device=device)\n",
    "        x_fake_labels = torch.randint(0, classes, (batch_size,), device=device)\n",
    "        x_fake = netG(z_noise, x_fake_labels)\n",
    "        y_fake_g = netD(x_fake, x_fake_labels)\n",
    "        g_loss = netD.loss(y_fake_g, real_label)\n",
    "        g_loss.backward()\n",
    "        optimizerG.step()\n",
    "\n",
    "        # Train D\n",
    "        netD.zero_grad()\n",
    "        y_real = netD(data, target)\n",
    "        d_real_loss = netD.loss(y_real, real_label)\n",
    "\n",
    "        y_fake_d = netD(x_fake.detach(), x_fake_labels)\n",
    "        d_fake_loss = netD.loss(y_fake_d, fake_label)\n",
    "        d_loss = (d_real_loss + d_fake_loss) / 2\n",
    "        d_loss.backward()\n",
    "        optimizerD.step()\n",
    "\n",
    "        if batch_idx % log_interval == 0 and batch_idx > 0:  \n",
    "            print('Epoch {} [{}/{}] loss_D: {:.4f} loss_G: {:.4f} time: {:.2f}'.format(\n",
    "                  epoch, batch_idx, len(dataloader),\n",
    "                  d_loss.mean().item(),\n",
    "                  g_loss.mean().item(),\n",
    "                  time.time() - batch_time))\n",
    "            vutils.save_image(data, os.path.join(out_dir, 'real_samples.png'), normalize=True)\n",
    "            with torch.no_grad():\n",
    "                viz_sample = netG(viz_noise, viz_label)\n",
    "                vutils.save_image(viz_sample, os.path.join(out_dir, 'fake_samples_{}.png'.format(epoch)), nrow=8, normalize=True)\n",
    "            batch_time = time.time()\n",
    "\n",
    "    save_to( name='CGAN_{}'.format(epoch))\n",
    "print('Total train time: {:.2f}'.format(time.time() - total_time))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BaM_qNTIdSh3",
    "outputId": "6878bd4b-aa49-4c91-a303-893d08236cf7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "m6c6xVCidBmM",
    "outputId": "bd029756-1006-4d3d-bec4-10f2daf2ebdd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.3.1\n",
      "Random Seed:  1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "VIZ_MODE=0\n",
    "CUDA = True\n",
    "data_dir = 'dataset/fashionmnist'\n",
    "class_dir = 'classes/9'\n",
    "out_dir = 'output/'\n",
    "epochs=3\n",
    "#LOG_FILE = os.path.join(OUT_PATH, 'log.txt')\n",
    "batch_size = 1\n",
    "lr = 0.0002\n",
    "latent_dim=100\n",
    "classes = 10\n",
    "img_size = 28\n",
    "log_interval=100\n",
    "channels=1\n",
    "train=True\n",
    "seed = 1\n",
    "\n",
    "#print(\"Logging to {}\\n\".format(LOG_FILE))\n",
    "#sys.stdout = utils.StdOut(LOG_FILE)\n",
    "CUDA = CUDA and torch.cuda.is_available()\n",
    "print(\"PyTorch version: {}\".format(torch.__version__))\n",
    "if CUDA:\n",
    "    print(\"CUDA version: {}\\n\".format(torch.version.cuda))\n",
    "\n",
    "if seed is None:\n",
    "    seed = np.random.randint(1, 10000)\n",
    "print(\"Random Seed: \", seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if CUDA:\n",
    "    torch.cuda.manual_seed(seed)\n",
    "cudnn.benchmark = True      # May train faster but cost more memory\n",
    "\n",
    "device = torch.device(\"cuda:0\" if CUDA else \"cpu\")\n",
    "netG = Generator(classes, channels, img_size, latent_dim).to(device)\n",
    "netG.load_state_dict(torch.load(os.path.join(out_dir, 'CGAN_199_G.pt'),map_location=torch.device('cpu')))\n",
    "netG.to(device)\n",
    "netD = Discriminator(classes, channels, img_size, latent_dim).to(device)\n",
    "\n",
    "netG.eval()\n",
    "netD.eval()\n",
    "if batch_size is None:\n",
    "    batch_size = data_loader.batch_size\n",
    "nrows = batch_size // 1\n",
    "if nrows == 0:\n",
    "    nrows =1\n",
    "for i in range(50):\n",
    "    viz_labels = np.array([num for _ in range(nrows) for num in range(9,10)])\n",
    "    viz_labels = torch.LongTensor(viz_labels).to(device)\n",
    "    # viz_label = torch.LongTensor(np.array([num for _ in range(nrows) for num in range(8)])).to(device)\n",
    "    # viz_onehot = _to_onehot(viz_label, dim=classes)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # z_noise = torch.randn(batch_size, latent_dim, device=device)\n",
    "        # x_fake_labels = torch.randint(0, classes, (batch_size,), device=device)\n",
    "        # x_fake = netG(z_noise, x_fake_labels)\n",
    "        viz_tensor = torch.randn(batch_size, latent_dim, device=device)\n",
    "        viz_sample = netG(viz_tensor, viz_labels)\n",
    "        viz_vector = to_np(viz_tensor).reshape(batch_size, latent_dim)\n",
    "        cur_time = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        np.savetxt('vec_{}.txt'.format(cur_time), viz_vector)\n",
    "        vutils.save_image(viz_sample, os.path.join(class_dir,'img_{}_{}.png'.format(cur_time,i)), nrow=1, normalize=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uSKo4JUi7cqi"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CGAN",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
